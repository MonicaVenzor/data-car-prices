{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ The goal of this challenge is to prepare a dataset and apply some feature selection techniques that you have learned so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöó We are dealing with a dataset about cars and we would like to predict whether a car is expensive or cheap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Checking whether a numerical feature has a normal distribution or not\n",
    "from statsmodels.graphics.gofplots import qqplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Cars_dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Go ahead and load the CSV into a dataframe called `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspiration</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginetype</th>\n",
       "      <th>cylindernumber</th>\n",
       "      <th>stroke</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>64.1</td>\n",
       "      <td>2548</td>\n",
       "      <td>dohc</td>\n",
       "      <td>four</td>\n",
       "      <td>2.68</td>\n",
       "      <td>5000</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>64.1</td>\n",
       "      <td>2548</td>\n",
       "      <td>dohc</td>\n",
       "      <td>four</td>\n",
       "      <td>2.68</td>\n",
       "      <td>5000</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>65.5</td>\n",
       "      <td>2823</td>\n",
       "      <td>ohcv</td>\n",
       "      <td>six</td>\n",
       "      <td>3.47</td>\n",
       "      <td>5000</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2337</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>3.40</td>\n",
       "      <td>5500</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>66.4</td>\n",
       "      <td>2824</td>\n",
       "      <td>ohc</td>\n",
       "      <td>five</td>\n",
       "      <td>3.40</td>\n",
       "      <td>5500</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  aspiration enginelocation carwidth  curbweight enginetype cylindernumber  \\\n",
       "0        std          front     64.1        2548       dohc           four   \n",
       "1        std          front     64.1        2548       dohc           four   \n",
       "2        std          front     65.5        2823       ohcv            six   \n",
       "3        std          front      NaN        2337        ohc           four   \n",
       "4        std          front     66.4        2824        ohc           five   \n",
       "\n",
       "   stroke  peakrpm      price  \n",
       "0    2.68     5000  expensive  \n",
       "1    2.68     5000  expensive  \n",
       "2    3.47     5000  expensive  \n",
       "3    3.40     5500  expensive  \n",
       "4    3.40     5500  expensive  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è The description of the dataset is available [here](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Cars_dataset_description.txt). Make sure to refer to it throughout the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Remove the duplicates from the dataset if there are any. ‚ùì\n",
    "\n",
    "*Overwite the dataframe `df`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df.duplicated().sum()\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Find the missing values and impute them either with `strategy = \"most frequent\"` (categorical variables) or `strategy = \"median\"` (numerical variables) ‚ùì\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enginelocation    5.235602\n",
       "carwidth          1.047120\n",
       "aspiration        0.000000\n",
       "curbweight        0.000000\n",
       "enginetype        0.000000\n",
       "cylindernumber    0.000000\n",
       "stroke            0.000000\n",
       "peakrpm           0.000000\n",
       "price             0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data_per = (df.isnull().sum().sort_values(ascending=False) / len(df)) * 100\n",
    "missing_data_per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora si podemos usar .select_dtypes para incluir o exluir datos utilizando el impute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.select_dtypes(exclude=['object']).columns\n",
    "numerical_imputer = SimpleImputer(strategy=\"median\")\n",
    "df[numerical_cols] = numerical_imputer.fit_transform(df[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aspiration        0.0\n",
       "enginelocation    0.0\n",
       "carwidth          0.0\n",
       "curbweight        0.0\n",
       "enginetype        0.0\n",
       "cylindernumber    0.0\n",
       "stroke            0.0\n",
       "peakrpm           0.0\n",
       "price             0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data_per = (df.isnull().sum().sort_values(ascending=False) / len(df)) * 100\n",
    "missing_data_per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `carwidth`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary> üí° <i>Hint</i> </summary>\n",
    "    <br>\n",
    "    ‚ÑπÔ∏è <code>carwidth</code> has multiple representations for missing values. Some are <code>np.nan</code>, some are  <code>*</code>. Once located, they can be imputed by the median value, since missing values make up less than 30% of the data.\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "df['carwidth'] = df['carwidth'].replace('*', np.nan)\n",
    "carwidth_median = df['carwidth'].median()\n",
    "df['carwidth'].fillna(carwidth_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_carwidth = df['carwidth'].isnull().sum()\n",
    "missing_carwidth "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `enginelocation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i> </summary>\n",
    "    <br>\n",
    "    ‚ÑπÔ∏è Considering that <code>enginelocation</code> is a categorical feature, and that the vast majority of the category is <code>front</code>, impute with the most frequent.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "enginelocation_mode = df['enginelocation'].mode()[0]\n",
    "df['enginelocation'].fillna(enginelocation_mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'front'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enginelocation_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TENER EN MENTE QUE SIN EL [0] ME DARIA LA SERIE, ES DECIR 0 > 'FRONT' Y CON EL [0] ACCEDO AL DATO DIRECTAMENTE Y ME QUEDO CON EL STRING 'front'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_enginelocation = df['enginelocation'].isnull().sum()\n",
    "missing_enginelocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /root/.pyenv/versions/3.10.6/envs/lewagon/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /root/code/MonicaVenzor/05-ML/02-Prepare-the-dataset/data-car-prices/tests\n",
      "plugins: anyio-3.6.2, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_missing_values.py::TestMissing_values::test_carwidth \u001b[32mPASSED\u001b[0m\u001b[32m         [ 50%]\u001b[0m\n",
      "test_missing_values.py::TestMissing_values::test_engine_location \u001b[32mPASSED\u001b[0m\u001b[32m  [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.58s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/missing_values.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed missing_values step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('missing_values',\n",
    "                         dataset = df)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Scaling the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 191 entries, 0 to 204\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   aspiration      191 non-null    object \n",
      " 1   enginelocation  191 non-null    object \n",
      " 2   carwidth        191 non-null    object \n",
      " 3   curbweight      191 non-null    float64\n",
      " 4   enginetype      191 non-null    object \n",
      " 5   cylindernumber  191 non-null    object \n",
      " 6   stroke          191 non-null    float64\n",
      " 7   peakrpm         191 non-null    float64\n",
      " 8   price           191 non-null    object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 14.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# As a reminder, some information about the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['curbweight', 'stroke', 'peakrpm'], dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here are the numerical features of the dataset we need to scale\n",
    "numerical_features = df.select_dtypes(exclude=['object']).columns\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: Scaling the numerical features** ‚ùì\n",
    "\n",
    "Investigate the numerical features for outliers and distribution, and apply the solutions below accordingly:\n",
    "- Robust Scaler\n",
    "- Standard Scaler\n",
    "\n",
    "Replace the original columns with the transformed values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `peakrpm` , `carwidth` , & `stroke`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i> </summary>\n",
    "\n",
    "    \n",
    "‚ÑπÔ∏è <code>peakrpm</code>, <code>carwidth</code>, & <code>stroke</code> have normal distributions but also some outliers. Hence, it is advisable to use `RobustScaler()`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `curbweight`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i> </summary>\n",
    "    <br>\n",
    "    ‚ÑπÔ∏è <code>curbweight</code> has a normal distribution and no outliers. It can be Standard Scaled.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /root/.pyenv/versions/3.10.6/envs/lewagon/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /root/code/MonicaVenzor/05-ML/02-Prepare-the-dataset/data-car-prices/tests\n",
      "plugins: anyio-3.6.2, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "test_scaling.py::TestScaling::test_carwidth \u001b[31mFAILED\u001b[0m\u001b[31m                       [ 25%]\u001b[0m\n",
      "test_scaling.py::TestScaling::test_curbweight \u001b[31mFAILED\u001b[0m\u001b[31m                     [ 50%]\u001b[0m\n",
      "test_scaling.py::TestScaling::test_peakrpm \u001b[31mFAILED\u001b[0m\u001b[31m                        [ 75%]\u001b[0m\n",
      "test_scaling.py::TestScaling::test_stroke \u001b[31mFAILED\u001b[0m\u001b[31m                         [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m__________________________ TestScaling.test_carwidth ___________________________\u001b[0m\n",
      "\n",
      "values = array(['64.1', '65.5', '66.5', '66.4', '66.3', '71.4', '66.5', '71.4',\n",
      "       '67.9', '64.8', '64.8', '64.8', '66.9', ...', '67.2',\n",
      "       '67.2', '67.2', '67.2', '67.2', '67.2', '68.9', '68.8', '68.9',\n",
      "       '68.9', '68.9'], dtype=object)\n",
      "\n",
      "    \u001b[37m@bottleneck_switch\u001b[39;49;00m()\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mnanmedian\u001b[39;49;00m(values, *, axis=\u001b[94mNone\u001b[39;49;00m, skipna=\u001b[94mTrue\u001b[39;49;00m, mask=\u001b[94mNone\u001b[39;49;00m):\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    values : ndarray\u001b[39;49;00m\n",
      "    \u001b[33m    axis : int, optional\u001b[39;49;00m\n",
      "    \u001b[33m    skipna : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m    mask : ndarray[bool], optional\u001b[39;49;00m\n",
      "    \u001b[33m        nan-mask if known\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns\u001b[39;49;00m\n",
      "    \u001b[33m    -------\u001b[39;49;00m\n",
      "    \u001b[33m    result : float\u001b[39;49;00m\n",
      "    \u001b[33m        Unless input is a float array, in which case use the same\u001b[39;49;00m\n",
      "    \u001b[33m        precision as the input array.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Examples\u001b[39;49;00m\n",
      "    \u001b[33m    --------\u001b[39;49;00m\n",
      "    \u001b[33m    >>> import pandas.core.nanops as nanops\u001b[39;49;00m\n",
      "    \u001b[33m    >>> s = pd.Series([1, np.nan, 2, 2])\u001b[39;49;00m\n",
      "    \u001b[33m    >>> nanops.nanmedian(s)\u001b[39;49;00m\n",
      "    \u001b[33m    2.0\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \n",
      "        \u001b[94mdef\u001b[39;49;00m \u001b[92mget_median\u001b[39;49;00m(x):\n",
      "            mask = notna(x)\n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m skipna \u001b[95mand\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m mask.all():\n",
      "                \u001b[94mreturn\u001b[39;49;00m np.nan\n",
      "            \u001b[94mwith\u001b[39;49;00m warnings.catch_warnings():\n",
      "                \u001b[90m# Suppress RuntimeWarning about All-NaN slice\u001b[39;49;00m\n",
      "                warnings.filterwarnings(\u001b[33m\"\u001b[39;49;00m\u001b[33mignore\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mAll-NaN slice encountered\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "                res = np.nanmedian(x[mask])\n",
      "            \u001b[94mreturn\u001b[39;49;00m res\n",
      "    \n",
      "        values, mask, dtype, _, _ = _get_values(values, skipna, mask=mask)\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m is_float_dtype(values.dtype):\n",
      "            \u001b[94mtry\u001b[39;49;00m:\n",
      ">               values = values.astype(\u001b[33m\"\u001b[39;49;00m\u001b[33mf8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\u001b[1m\u001b[31mE               ValueError: could not convert string to float: '*'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/root/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/nanops.py\u001b[0m:752: ValueError\n",
      "\n",
      "\u001b[33mThe above exception was the direct cause of the following exception:\u001b[0m\n",
      "\n",
      "self = <tests.test_scaling.TestScaling testMethod=test_carwidth>\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_carwidth\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.dataset.carwidth.median() , \u001b[94m0\u001b[39;49;00m)\n",
      "\n",
      "\u001b[1m\u001b[31mtest_scaling.py\u001b[0m:7: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/root/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m:11194: in median\n",
      "    \u001b[94mreturn\u001b[39;49;00m NDFrame.median(\u001b[96mself\u001b[39;49;00m, axis, skipna, level, numeric_only, **kwargs)\n",
      "\u001b[1m\u001b[31m/root/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m:10706: in median\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._stat_function(\n",
      "\u001b[1m\u001b[31m/root/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m:10646: in _stat_function\n",
      "    \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._reduce(\n",
      "\u001b[1m\u001b[31m/root/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/series.py\u001b[0m:4471: in _reduce\n",
      "    \u001b[94mreturn\u001b[39;49;00m op(delegate, skipna=skipna, **kwds)\n",
      "\u001b[1m\u001b[31m/root/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/nanops.py\u001b[0m:155: in f\n",
      "    result = alt(values, axis=axis, skipna=skipna, **kwds)\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "values = array(['64.1', '65.5', '66.5', '66.4', '66.3', '71.4', '66.5', '71.4',\n",
      "       '67.9', '64.8', '64.8', '64.8', '66.9', ...', '67.2',\n",
      "       '67.2', '67.2', '67.2', '67.2', '67.2', '68.9', '68.8', '68.9',\n",
      "       '68.9', '68.9'], dtype=object)\n",
      "\n",
      "    \u001b[37m@bottleneck_switch\u001b[39;49;00m()\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mnanmedian\u001b[39;49;00m(values, *, axis=\u001b[94mNone\u001b[39;49;00m, skipna=\u001b[94mTrue\u001b[39;49;00m, mask=\u001b[94mNone\u001b[39;49;00m):\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Parameters\u001b[39;49;00m\n",
      "    \u001b[33m    ----------\u001b[39;49;00m\n",
      "    \u001b[33m    values : ndarray\u001b[39;49;00m\n",
      "    \u001b[33m    axis : int, optional\u001b[39;49;00m\n",
      "    \u001b[33m    skipna : bool, default True\u001b[39;49;00m\n",
      "    \u001b[33m    mask : ndarray[bool], optional\u001b[39;49;00m\n",
      "    \u001b[33m        nan-mask if known\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns\u001b[39;49;00m\n",
      "    \u001b[33m    -------\u001b[39;49;00m\n",
      "    \u001b[33m    result : float\u001b[39;49;00m\n",
      "    \u001b[33m        Unless input is a float array, in which case use the same\u001b[39;49;00m\n",
      "    \u001b[33m        precision as the input array.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Examples\u001b[39;49;00m\n",
      "    \u001b[33m    --------\u001b[39;49;00m\n",
      "    \u001b[33m    >>> import pandas.core.nanops as nanops\u001b[39;49;00m\n",
      "    \u001b[33m    >>> s = pd.Series([1, np.nan, 2, 2])\u001b[39;49;00m\n",
      "    \u001b[33m    >>> nanops.nanmedian(s)\u001b[39;49;00m\n",
      "    \u001b[33m    2.0\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \n",
      "        \u001b[94mdef\u001b[39;49;00m \u001b[92mget_median\u001b[39;49;00m(x):\n",
      "            mask = notna(x)\n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m skipna \u001b[95mand\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m mask.all():\n",
      "                \u001b[94mreturn\u001b[39;49;00m np.nan\n",
      "            \u001b[94mwith\u001b[39;49;00m warnings.catch_warnings():\n",
      "                \u001b[90m# Suppress RuntimeWarning about All-NaN slice\u001b[39;49;00m\n",
      "                warnings.filterwarnings(\u001b[33m\"\u001b[39;49;00m\u001b[33mignore\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mAll-NaN slice encountered\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "                res = np.nanmedian(x[mask])\n",
      "            \u001b[94mreturn\u001b[39;49;00m res\n",
      "    \n",
      "        values, mask, dtype, _, _ = _get_values(values, skipna, mask=mask)\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m is_float_dtype(values.dtype):\n",
      "            \u001b[94mtry\u001b[39;49;00m:\n",
      "                values = values.astype(\u001b[33m\"\u001b[39;49;00m\u001b[33mf8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            \u001b[94mexcept\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m \u001b[94mas\u001b[39;49;00m err:\n",
      "                \u001b[90m# e.g. \"could not convert string to float: 'a'\"\u001b[39;49;00m\n",
      ">               \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\u001b[96mstr\u001b[39;49;00m(err)) \u001b[94mfrom\u001b[39;49;00m \u001b[04m\u001b[96merr\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               TypeError: could not convert string to float: '*'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/root/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/nanops.py\u001b[0m:755: TypeError\n",
      "\u001b[31m\u001b[1m_________________________ TestScaling.test_curbweight __________________________\u001b[0m\n",
      "\n",
      "self = <tests.test_scaling.TestScaling testMethod=test_curbweight>\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_curbweight\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.dataset.curbweight.max() < \u001b[94m3\u001b[39;49;00m, \u001b[94mTrue\u001b[39;49;00m)\n",
      "\u001b[1m\u001b[31mE       AssertionError: False != True\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_scaling.py\u001b[0m:11: AssertionError\n",
      "\u001b[31m\u001b[1m___________________________ TestScaling.test_peakrpm ___________________________\u001b[0m\n",
      "\n",
      "self = <tests.test_scaling.TestScaling testMethod=test_peakrpm>\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_peakrpm\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.dataset.peakrpm.median(), \u001b[94m0\u001b[39;49;00m)\n",
      "\u001b[1m\u001b[31mE       AssertionError: 5100.0 != 0\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_scaling.py\u001b[0m:5: AssertionError\n",
      "\u001b[31m\u001b[1m___________________________ TestScaling.test_stroke ____________________________\u001b[0m\n",
      "\n",
      "self = <tests.test_scaling.TestScaling testMethod=test_stroke>\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_stroke\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.dataset.stroke.median() , \u001b[94m0\u001b[39;49;00m)\n",
      "\u001b[1m\u001b[31mE       AssertionError: 3.29 != 0\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_scaling.py\u001b[0m:9: AssertionError\n",
      "=========================== short test summary info ============================\n",
      "FAILED test_scaling.py::TestScaling::test_carwidth - TypeError: could not con...\n",
      "FAILED test_scaling.py::TestScaling::test_curbweight - AssertionError: False ...\n",
      "FAILED test_scaling.py::TestScaling::test_peakrpm - AssertionError: 5100.0 != 0\n",
      "FAILED test_scaling.py::TestScaling::test_stroke - AssertionError: 3.29 != 0\n",
      "\u001b[31m============================== \u001b[31m\u001b[1m4 failed\u001b[0m\u001b[31m in 0.46s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/scaling.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed scaling step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('scaling',\n",
    "                         dataset = df\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Encoding the categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: encoding the categorical variables** ‚ùì\n",
    "\n",
    "üëá Investigate the features that require encoding, and apply the following techniques accordingly:\n",
    "\n",
    "- One-hot encoding\n",
    "- Manual ordinal encoding\n",
    "\n",
    "In the Dataframe, replace the original features with their encoded version(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `aspiration` & `enginelocation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i> </summary>\n",
    "    <br>\n",
    "    ‚ÑπÔ∏è <code>aspiration</code> and <code>enginelocation</code> are binary categorical features.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `enginetype`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i> </summary>\n",
    "    <br>\n",
    "    ‚ÑπÔ∏è <code>enginetype</code> is a multicategorical feature and must be One hot encoded.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `cylindernumber`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° Hint </summary>\n",
    "\n",
    "‚ÑπÔ∏è <code>cylindernumber</code> is an ordinal feature and must be manually encoded into numeric.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Now that you've made `cylindernumber` into a numeric feature between 2 and 12, you need to scale it ‚ùì\n",
    "\n",
    "<br/>\n",
    "\n",
    "<details>\n",
    "    <summary>üí° Hint </summary>\n",
    "\n",
    "Look at the current distribution of the `cylindernumber` and ask yourself the following questions:\n",
    "- Does scaling affect a feature's distribution ?\n",
    "- According to the distribution of this feature, what is the most appropriate scaling method?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><i>Here is a screenshot of how your dataframe shoud look like after scaling and encoding</i></summary>\n",
    "    \n",
    "    \n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/02-Prepare-the-dataset/car_price_after_scaling_and_encoding.png\">    \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `price`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Encode the target `price`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° Hint </summary>\n",
    "    <br>\n",
    "    ‚ÑπÔ∏è <code>price</code> is the target and must be Label encoded.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /root/.pyenv/versions/3.10.6/envs/lewagon/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /root/code/MonicaVenzor/05-ML/02-Prepare-the-dataset/data-car-prices/tests\n",
      "plugins: anyio-3.6.2, asyncio-0.19.0\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "test_encoding.py::TestEncoding::test_aspiration \u001b[31mFAILED\u001b[0m\u001b[31m                   [ 25%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_enginelocation \u001b[31mFAILED\u001b[0m\u001b[31m               [ 50%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_enginetype \u001b[31mFAILED\u001b[0m\u001b[31m                   [ 75%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_price \u001b[31mFAILED\u001b[0m\u001b[31m                        [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_________________________ TestEncoding.test_aspiration _________________________\u001b[0m\n",
      "\n",
      "self = <tests.test_encoding.TestEncoding testMethod=test_aspiration>\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_aspiration\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.dataset.aspiration.max(), \u001b[94m1\u001b[39;49;00m)\n",
      "\u001b[1m\u001b[31mE       AssertionError: 'turbo' != 1\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_encoding.py\u001b[0m:5: AssertionError\n",
      "\u001b[31m\u001b[1m_______________________ TestEncoding.test_enginelocation _______________________\u001b[0m\n",
      "\n",
      "self = <tests.test_encoding.TestEncoding testMethod=test_enginelocation>\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_enginelocation\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.dataset.enginelocation.max(), \u001b[94m1\u001b[39;49;00m)\n",
      "\u001b[1m\u001b[31mE       AssertionError: 'rear' != 1\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_encoding.py\u001b[0m:7: AssertionError\n",
      "\u001b[31m\u001b[1m_________________________ TestEncoding.test_enginetype _________________________\u001b[0m\n",
      "\n",
      "self = <tests.test_encoding.TestEncoding testMethod=test_enginetype>\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_enginetype\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.result.dataset.columns) > \u001b[94m13\u001b[39;49;00m, \u001b[94mTrue\u001b[39;49;00m)\n",
      "\u001b[1m\u001b[31mE       AssertionError: False != True\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_encoding.py\u001b[0m:9: AssertionError\n",
      "\u001b[31m\u001b[1m___________________________ TestEncoding.test_price ____________________________\u001b[0m\n",
      "\n",
      "self = <tests.test_encoding.TestEncoding testMethod=test_price>\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_price\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.dataset.price.max(), \u001b[94m1\u001b[39;49;00m)\n",
      "\u001b[1m\u001b[31mE       AssertionError: 'expensive' != 1\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_encoding.py\u001b[0m:13: AssertionError\n",
      "=========================== short test summary info ============================\n",
      "FAILED test_encoding.py::TestEncoding::test_aspiration - AssertionError: 'tur...\n",
      "FAILED test_encoding.py::TestEncoding::test_enginelocation - AssertionError: ...\n",
      "FAILED test_encoding.py::TestEncoding::test_enginetype - AssertionError: Fals...\n",
      "FAILED test_encoding.py::TestEncoding::test_price - AssertionError: 'expensiv...\n",
      "\u001b[31m============================== \u001b[31m\u001b[1m4 failed\u001b[0m\u001b[31m in 0.30s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/encoding.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed encoding step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('encoding',\n",
    "                         dataset = df)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Base Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëè The dataset has been preprocessed and is now ready to be fitted to a model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì**Question: a first attempt to evaluate a classification model** ‚ùì\n",
    "\n",
    "Cross-validate a `LogisticRegression` on this preprocessed dataset and save its score under a variable named `base_model_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_model_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnbresult\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChallengeResult\n\u001b[1;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m ChallengeResult(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_model\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 4\u001b[0m                          score \u001b[38;5;241m=\u001b[39m \u001b[43mbase_model_score\u001b[49m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m result\u001b[38;5;241m.\u001b[39mwrite()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mcheck())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'base_model_score' is not defined"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('base_model',\n",
    "                         score = base_model_score\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Feature Selection (with _Permutation Importance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë©üèª‚Äçüè´ A powerful way to detect whether a feature is relevant or not to predict a target is to:\n",
    "1. Run a model and score it\n",
    "2. Shuffle this feature, re-run the model and score it\n",
    "    - If the performance significantly dropped, the feature is important and you shoudn't have dropped it\n",
    "    - If the performance didn't decrease a lot, the feature may be discarded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** ‚ùì\n",
    "\n",
    "1. Perform a feature permutation to detect which features bring the least amount of information to the model. \n",
    "2. Remove the weak features from your dataset until you notice model performance dropping substantially\n",
    "3. Using your new set of strong features, cross-validate a new model, and save its score under variable name `strong_model_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('strong_model',\n",
    "                         score = strong_model_score\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus - Stratifying your data ‚öñÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° As we split our data into training and testing, we need to be mindful of the proportion of categorical variables in our dataset - whether it's the classes of our target `y` or a categorical feature in `X`.\n",
    "\n",
    "Let's have a look at an example üëá\n",
    "\n",
    "‚ùì Split your original `X` and `y` into training and testing data, using sklearn's `train_test_split`; use `random_state=1` and `test_size=0.3` to have comparable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Check the proportion of `price` class `1` cars in your training dataset and testing dataset.\n",
    "\n",
    "> _If you check the proportion of them in the raw `df`, it should be very close to 50/50_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should still be pretty close to 50/50 ‚òùÔ∏è \n",
    "\n",
    "***But what if we change the random state?*** \n",
    "\n",
    "‚ùì Loop through random states 1 through 10, each time calculating the share of `price` class `1` cars in the training and testing data. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will observe that the proportion changes every time, sometimes even quite drastically üò±! This can affect model performance!\n",
    "\n",
    "‚ùì Compare the test score of a logistic regression when trained using `train_test_split(random_state=1)` _vs._ `random_state=9` ‚ùì \n",
    "\n",
    "Remember to fit on training data and score on testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÄ You should see a much lower score with `random_state=9` because the proportion of class `1` cars in that test set is 34.5%, quite far from the 57.9% in the training set or even the 50% in the original dataset.\n",
    "\n",
    "This is substantial, as this accidental imbalance in our dataset can not only make model performance worse, but also distort the \"reality\" during training or scoring üßê"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***So how do we fix this issue? How do we keep the same distribution of classes across the train set and the test set? üîß***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéÅ Luckily, this is taken care of by `cross_validate` in sklearn, when the estimator (a.k.a the model) is a classifier and the target is a class. Check out the documentation of the `cv` parameter in üìö [**sklearn.model_selection.cross_validate**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html).\n",
    "\n",
    "The answer is to use the following:\n",
    "\n",
    ">üìö [**Stratification**](https://scikit-learn.org/stable/modules/cross_validation.html#stratification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratification of the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° We can also use the ***strafification*** technique in a `train_test_split`.\n",
    "\n",
    "‚ùì Run through the same 1 to 10 random state loop again, but this time also ***pass `stratify=y` into the holdout method***. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÄ Even if the random state is changing, the proportion of classes inside the training and testing data is kept the same as in the original `y`. This is what _stratification_ is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `train_test_split` with the `stratify` parameter, we can also preserve proportions of a feature across training and testing data. This can be extremely important, for example:\n",
    "\n",
    "- preserving proportion of male and female customers in predicting churn üôã‚Äç‚ôÇÔ∏è üôã\n",
    "- preserving the proportion big and small houses in predicting their prices üè† üè∞\n",
    "- preserving distribution of 1-5 review scores (multiclass!) in recommending the next product üõçÔ∏è\n",
    "- etc...\n",
    "\n",
    "For instance, in our dataset, to holdout the same share of `aspiration` feature in both training and testing data, we could simply write `train_test_split(X, y, test_size=0.3, stratify=X.aspiration)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw, **`cross_validate` [can automatically stratify the target](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#:~:text=For%20int/None%20inputs%2C%20if%20the%20estimator%20is%20a%20classifier%20and%20y%20is%20either%20binary%20or%20multiclass%2C%20StratifiedKFold%20is%20used.), but not the features...** ü§î We need a bit of extra work for that.\n",
    "\n",
    "We need `StratifiedKFold` üî¨\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratification - generalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìö [**StratifiedKFold**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) allows us to split the data into `K` splits, while stratifying on certain columns (features or target).\n",
    "\n",
    "This way, we can do a manual cross-validation while keeping proportions on the categorical features of interest - let's try it with the binary `aspiration` feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# initializing a stratified k-fold that will split the data into 5 folds\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "scores = []\n",
    "\n",
    "# .split() method creates an iterator; 'X.aspiration' is the feature that we stratify by\n",
    "for train_indices, test_indices in skf.split(X, X.aspiration):\n",
    "\n",
    "    # 'train_indices' and 'test_indices' are lists of indices that produce proportional splits\n",
    "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "    # initialize and fit a model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # append a score to get an average of 5 folds in the end\n",
    "    scores.append(model.score(X_test, y_test))\n",
    "\n",
    "np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìñ Some sklearn reads on **stratification**:\n",
    "\n",
    "- [Visualization of how different holdout methods in sklearn work](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py)\n",
    "- [Overall cross-validation and stratification understanding](https://scikit-learn.org/stable/modules/cross_validation.html#stratification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! You have prepared a whole dataset, ran feature selection and even learned about stratification üí™\n",
    "\n",
    "üíæ Don't forget to git add/commit/push your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
